{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDbJWoO1yO8e"
      },
      "source": [
        "# Image Classification with CNN - LeNet5 architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzQxqD6HyO8i"
      },
      "source": [
        "In this exercise, we will apply the LeNet5 algorithm to the Fashion MNIST dataset and improve your performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFyVotRvyO8j"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTHLyL1fyO8j",
        "outputId": "8ce57c91-7b59-433c-c491-2d1c0e8e9f5f",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# TODO: Load the dataset\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# # # If your computer is slow, try to use a subset of data, e.g.\n",
        "# X_train = X_train[:10000]\n",
        "# y_train = y_train[:10000]\n",
        "# X_test = X_test[:2000]\n",
        "# y_test = y_test[:2000]\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8ShXIANyO8l"
      },
      "source": [
        "As you already know, this dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BvNG0PbyO8l"
      },
      "source": [
        "You can have a look at some images if needed, even if you already know them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "lnjqgv-GyO8m",
        "outputId": "dac567f0-2518-4198-bdd4-4e0bc4edfc25",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx], cmap=\"gray_r\")\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdYH6XW1yO8n"
      },
      "source": [
        "Make the data preparation and preprocessing: scale and reshape the data, put the labels to the good shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fjv8XMPByO8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a426e89-bf14-4da3-b7aa-e8d900b0039f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes = 10)\n",
        "y_test_cat = to_categorical(y_test, num_classes = 10)\n",
        "\n",
        "X_train_norm = X_train/255\n",
        "X_test_norm = X_test/255\n",
        "\n",
        "\n",
        "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], 28, 28, 1)\n",
        "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], 28, 28, 1)\n",
        "\n",
        "X_train_norm.shape #Should be (60000, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9LKzxR9yO8o"
      },
      "source": [
        "Now build the LeNet5 architecture. You can reuse the one of the course, or try to build it by yourself.\n",
        "\n",
        "The architecture is the following:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1WteTU2FPIVMkBKmMxGpFm5OjsX-szTbB\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GKyMFlL6yO8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b1e8267-b7c3-49dd-95fd-d368b81f6538"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " C1 (Conv2D)                 (None, 26, 26, 6)         60        \n",
            "                                                                 \n",
            " S2 (MaxPooling2D)           (None, 13, 13, 6)         0         \n",
            "                                                                 \n",
            " C3 (Conv2D)                 (None, 11, 11, 16)        880       \n",
            "                                                                 \n",
            " S4 (MaxPooling2D)           (None, 5, 5, 16)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 400)               0         \n",
            "                                                                 \n",
            " C5 (Dense)                  (None, 120)               48120     \n",
            "                                                                 \n",
            " C6 (Dense)                  (None, 84)                10164     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60,074\n",
            "Trainable params: 60,074\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense\n",
        "\n",
        "\n",
        "def lenet5():\n",
        "    \n",
        "    model = Sequential()\n",
        "\n",
        "    # Layer C1\n",
        "    model.add(Conv2D(filters=6, name='C1', kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "    # Layer S2\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S2'))\n",
        "    # Layer C3\n",
        "    model.add(Conv2D(filters=16, name='C3', kernel_size=(3, 3), activation='relu'))\n",
        "    # Layer S4\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S4'))\n",
        "    # Before going into layer C5, we flatten our units\n",
        "    model.add(Flatten())\n",
        "    # Layer C5\n",
        "    model.add(Dense(120, activation = 'relu', name = 'C5'))\n",
        "    # Layer F6\n",
        "    model.add(Dense(84, activation = 'relu', name = 'C6'))\n",
        "    # Output layer\n",
        "    model.add(Dense(units=10, activation = 'softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "lenet5().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1qBEauqyO8p"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPL3aKnyyO8p",
        "outputId": "b5873f9f-62b8-49f3-c69e-479cc9f493cd",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "30/30 [==============================] - 13s 36ms/step - loss: 1.4965 - accuracy: 0.5446 - val_loss: 0.8618 - val_accuracy: 0.6893\n",
            "Epoch 2/30\n",
            "30/30 [==============================] - 0s 17ms/step - loss: 0.7266 - accuracy: 0.7367 - val_loss: 0.6664 - val_accuracy: 0.7548\n",
            "Epoch 3/30\n",
            "30/30 [==============================] - 0s 17ms/step - loss: 0.6045 - accuracy: 0.7774 - val_loss: 0.5892 - val_accuracy: 0.7760\n",
            "Epoch 4/30\n",
            "30/30 [==============================] - 0s 17ms/step - loss: 0.5429 - accuracy: 0.8022 - val_loss: 0.5455 - val_accuracy: 0.8000\n",
            "Epoch 5/30\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.5056 - accuracy: 0.8165 - val_loss: 0.5113 - val_accuracy: 0.8167\n",
            "Epoch 6/30\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.4776 - accuracy: 0.8286 - val_loss: 0.4995 - val_accuracy: 0.8229\n",
            "Epoch 7/30\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.4619 - accuracy: 0.8357 - val_loss: 0.4856 - val_accuracy: 0.8259\n",
            "Epoch 8/30\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4546 - accuracy: 0.8366 - val_loss: 0.4832 - val_accuracy: 0.8267\n",
            "Epoch 9/30\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.4323 - accuracy: 0.8479 - val_loss: 0.4642 - val_accuracy: 0.8310\n",
            "Epoch 10/30\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.4228 - accuracy: 0.8503 - val_loss: 0.4472 - val_accuracy: 0.8366\n",
            "Epoch 11/30\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.4113 - accuracy: 0.8541 - val_loss: 0.4406 - val_accuracy: 0.8410\n",
            "Epoch 12/30\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4061 - accuracy: 0.8547 - val_loss: 0.4180 - val_accuracy: 0.8506\n",
            "Epoch 13/30\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3924 - accuracy: 0.8601 - val_loss: 0.4342 - val_accuracy: 0.8405\n",
            "Epoch 14/30\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3888 - accuracy: 0.8605 - val_loss: 0.4098 - val_accuracy: 0.8535\n",
            "Epoch 15/30\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.3777 - accuracy: 0.8648 - val_loss: 0.4009 - val_accuracy: 0.8560\n",
            "Epoch 16/30\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3721 - accuracy: 0.8665 - val_loss: 0.3999 - val_accuracy: 0.8599\n",
            "Epoch 17/30\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3671 - accuracy: 0.8671 - val_loss: 0.3943 - val_accuracy: 0.8579\n",
            "Epoch 18/30\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3592 - accuracy: 0.8712 - val_loss: 0.3812 - val_accuracy: 0.8660\n",
            "Epoch 19/30\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3544 - accuracy: 0.8719 - val_loss: 0.3838 - val_accuracy: 0.8645\n",
            "Epoch 20/30\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3463 - accuracy: 0.8755 - val_loss: 0.3715 - val_accuracy: 0.8700\n",
            "Epoch 21/30\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3465 - accuracy: 0.8750 - val_loss: 0.3830 - val_accuracy: 0.8615\n",
            "Epoch 22/30\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3427 - accuracy: 0.8765 - val_loss: 0.3692 - val_accuracy: 0.8676\n",
            "Epoch 23/30\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.3365 - accuracy: 0.8781 - val_loss: 0.3640 - val_accuracy: 0.8705\n",
            "Epoch 24/30\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3336 - accuracy: 0.8793 - val_loss: 0.3649 - val_accuracy: 0.8690\n",
            "Epoch 25/30\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3247 - accuracy: 0.8827 - val_loss: 0.3552 - val_accuracy: 0.8740\n",
            "Epoch 26/30\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3210 - accuracy: 0.8847 - val_loss: 0.3564 - val_accuracy: 0.8735\n",
            "Epoch 27/30\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3224 - accuracy: 0.8832 - val_loss: 0.3498 - val_accuracy: 0.8741\n",
            "Epoch 28/30\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.3146 - accuracy: 0.8855 - val_loss: 0.3452 - val_accuracy: 0.8782\n",
            "Epoch 29/30\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.3126 - accuracy: 0.8864 - val_loss: 0.3545 - val_accuracy: 0.8733\n",
            "Epoch 30/30\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.3115 - accuracy: 0.8873 - val_loss: 0.3487 - val_accuracy: 0.8754\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f996012f820>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# TODO: Compile and fit your model\n",
        "import os\n",
        "\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True' #https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "model = lenet5()\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define now our callbacks\n",
        "# callbacks = [EarlyStopping(monitor='val_loss', patience=10), TensorBoard(log_dir='./keras-logs', histogram_freq=0, write_graph=True, write_images=True)]\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
        "\n",
        "# Finally fit the model\n",
        "model.fit(x=X_train_norm, y=y_train_cat, validation_data=(X_test_norm, y_test_cat), epochs=30, batch_size=2048, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf-SqjjOyO8q"
      },
      "source": [
        "Have a look at the tensorboard and see if it gives a deeper understanding of your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2FTj7TSyO8q"
      },
      "source": [
        "Compute then the accuracy of your model. Is it better than a regular MLP used before?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPjJoMQZyO8q",
        "outputId": "b3afbfcd-6efd-4345-9b29-efc617f88f02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59/59 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 10ms/step\n",
            "accuracy on train with CNN: 0.8865166666666666\n",
            "accuracy on test with CNN: 0.8754\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size = 1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size = batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size = batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with CNN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with CNN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vulsgHiyO8q"
      },
      "source": [
        "We will now add image augmentation to improve our results, especially we will try to reduce overfitting this way.\n",
        "\n",
        "To do so, you can use `ImageDataGenerator` from Keras that makes all the work for you (including rescaling), with the following parameter: \n",
        "* `horizontal_flip=True`\n",
        "\n",
        "For more info about how the `ImageDataGenerator` works, you can check out [this article](https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/).\n",
        "\n",
        "Begin by creating an object `ImageDataGenerator` with this parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-19T11:58:37.442182Z",
          "start_time": "2020-08-19T11:58:37.438397Z"
        },
        "id": "pas-fMSIyO8q"
      },
      "outputs": [],
      "source": [
        "# TODO: Instantiate an ImageDataGenerator object\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7nCnu9syO8r"
      },
      "source": [
        "Finally, you can train your model using this generator, with the method `fit_generator` of your model and the method `flow` of your `ImageDataGenerator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt6wXa3IyO8r",
        "outputId": "edae04b7-3965-491b-edec-49694b6b1331",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-2e9d6b0e4371>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 4s 56ms/step - loss: 0.5080 - accuracy: 0.8342 - val_loss: 0.3717 - val_accuracy: 0.8679\n",
            "Epoch 2/30\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.3625 - accuracy: 0.8678 - val_loss: 0.3579 - val_accuracy: 0.8726\n",
            "Epoch 3/30\n",
            "58/58 [==============================] - 3s 56ms/step - loss: 0.3428 - accuracy: 0.8759 - val_loss: 0.3467 - val_accuracy: 0.8744\n",
            "Epoch 4/30\n",
            "58/58 [==============================] - 6s 94ms/step - loss: 0.3306 - accuracy: 0.8814 - val_loss: 0.3465 - val_accuracy: 0.8757\n",
            "Epoch 5/30\n",
            "58/58 [==============================] - 3s 47ms/step - loss: 0.3236 - accuracy: 0.8831 - val_loss: 0.3357 - val_accuracy: 0.8798\n",
            "Epoch 6/30\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.3177 - accuracy: 0.8847 - val_loss: 0.3401 - val_accuracy: 0.8785\n",
            "Epoch 7/30\n",
            "58/58 [==============================] - 5s 88ms/step - loss: 0.3089 - accuracy: 0.8893 - val_loss: 0.3289 - val_accuracy: 0.8827\n",
            "Epoch 8/30\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.3060 - accuracy: 0.8898 - val_loss: 0.3414 - val_accuracy: 0.8745\n",
            "Epoch 9/30\n",
            "58/58 [==============================] - 4s 65ms/step - loss: 0.3044 - accuracy: 0.8903 - val_loss: 0.3278 - val_accuracy: 0.8837\n",
            "Epoch 10/30\n",
            "58/58 [==============================] - 4s 62ms/step - loss: 0.2975 - accuracy: 0.8928 - val_loss: 0.3331 - val_accuracy: 0.8805\n",
            "Epoch 11/30\n",
            "58/58 [==============================] - 4s 63ms/step - loss: 0.2955 - accuracy: 0.8936 - val_loss: 0.3243 - val_accuracy: 0.8856\n",
            "Epoch 12/30\n",
            "58/58 [==============================] - 3s 60ms/step - loss: 0.2940 - accuracy: 0.8931 - val_loss: 0.3222 - val_accuracy: 0.8857\n",
            "Epoch 13/30\n",
            "58/58 [==============================] - 3s 45ms/step - loss: 0.2883 - accuracy: 0.8955 - val_loss: 0.3228 - val_accuracy: 0.8830\n",
            "Epoch 14/30\n",
            "58/58 [==============================] - 4s 63ms/step - loss: 0.2846 - accuracy: 0.8972 - val_loss: 0.3204 - val_accuracy: 0.8855\n",
            "Epoch 15/30\n",
            "58/58 [==============================] - 3s 56ms/step - loss: 0.2857 - accuracy: 0.8949 - val_loss: 0.3173 - val_accuracy: 0.8859\n",
            "Epoch 16/30\n",
            "58/58 [==============================] - 3s 55ms/step - loss: 0.2786 - accuracy: 0.8999 - val_loss: 0.3144 - val_accuracy: 0.8893\n",
            "Epoch 17/30\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.2740 - accuracy: 0.9003 - val_loss: 0.3161 - val_accuracy: 0.8887\n",
            "Epoch 18/30\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.2729 - accuracy: 0.8992 - val_loss: 0.3159 - val_accuracy: 0.8870\n",
            "Epoch 19/30\n",
            "58/58 [==============================] - 4s 61ms/step - loss: 0.2708 - accuracy: 0.9017 - val_loss: 0.3107 - val_accuracy: 0.8896\n",
            "Epoch 20/30\n",
            "58/58 [==============================] - 3s 55ms/step - loss: 0.2715 - accuracy: 0.9016 - val_loss: 0.3130 - val_accuracy: 0.8876\n",
            "Epoch 21/30\n",
            "58/58 [==============================] - 3s 44ms/step - loss: 0.2655 - accuracy: 0.9039 - val_loss: 0.3094 - val_accuracy: 0.8905\n",
            "Epoch 22/30\n",
            "58/58 [==============================] - 3s 51ms/step - loss: 0.2632 - accuracy: 0.9041 - val_loss: 0.3079 - val_accuracy: 0.8900\n",
            "Epoch 23/30\n",
            "58/58 [==============================] - 3s 55ms/step - loss: 0.2608 - accuracy: 0.9054 - val_loss: 0.3122 - val_accuracy: 0.8881\n",
            "Epoch 24/30\n",
            "58/58 [==============================] - 3s 56ms/step - loss: 0.2609 - accuracy: 0.9039 - val_loss: 0.3060 - val_accuracy: 0.8926\n",
            "Epoch 25/30\n",
            "58/58 [==============================] - 3s 44ms/step - loss: 0.2633 - accuracy: 0.9028 - val_loss: 0.3013 - val_accuracy: 0.8931\n",
            "Epoch 26/30\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.2559 - accuracy: 0.9060 - val_loss: 0.3026 - val_accuracy: 0.8933\n",
            "Epoch 27/30\n",
            "58/58 [==============================] - 4s 62ms/step - loss: 0.2522 - accuracy: 0.9070 - val_loss: 0.3053 - val_accuracy: 0.8912\n",
            "Epoch 28/30\n",
            "58/58 [==============================] - 3s 45ms/step - loss: 0.2491 - accuracy: 0.9087 - val_loss: 0.2994 - val_accuracy: 0.8927\n",
            "Epoch 29/30\n",
            "58/58 [==============================] - 3s 55ms/step - loss: 0.2510 - accuracy: 0.9081 - val_loss: 0.2949 - val_accuracy: 0.8951\n",
            "Epoch 30/30\n",
            "58/58 [==============================] - 4s 61ms/step - loss: 0.2458 - accuracy: 0.9104 - val_loss: 0.2949 - val_accuracy: 0.8952\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f989c1aeec0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# TODO: train your model\n",
        "batch_size = 1024\n",
        "model.fit_generator(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n",
        "                    validation_data=(X_test_norm, y_test_cat), callbacks=callbacks,\n",
        "                    steps_per_epoch=len(X_train_norm) / batch_size, epochs=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuzFke8pyO8r"
      },
      "source": [
        "Recompute the accuracy of your model, does it improve your performances with data augmentation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsTm86tuyO8r",
        "outputId": "bdc2237c-857e-4beb-f464-240505c5e2c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59/59 [==============================] - 0s 5ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "accuracy on train with NN: 0.9142166666666667\n",
            "accuracy on test with NN: 0.8952\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size=1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size = batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size = batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with NN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with NN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOzkdGf7yO8s"
      },
      "source": [
        "You can now try to improve even more your results. For example, add more parameters to your `ImageDataGenerator`, play with some hyperparameters, and so on..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}